---
title: "Pre-Course Assignment"
description: "This small portfolio was created as a pre-course, which means before any classes in R at LBS where taken"
slug: pre_course
image: desperate.jpg
keywords: ""
categories: 
    - ""
    - ""
date: 2022-08-31
draft: false
---



<p>The goal is to test your software installation, to demonstrate
competency in Markdown, and in the basics of <code>ggplot</code>.</p>
<div id="task-2-gapminder-country-comparison" class="section level1">
<h1>Task 2: <code>gapminder</code> country comparison</h1>
<pre class="r"><code>glimpse(gapminder)</code></pre>
<pre><code>## Rows: 1,704
## Columns: 6
## $ country   &lt;fct&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, …
## $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, …
## $ year      &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, …
## $ lifeExp   &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8…
## $ pop       &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12…
## $ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, …</code></pre>
<pre class="r"><code>head(gapminder, 20) # look at the first 20 rows of the dataframe</code></pre>
<pre><code>## # A tibble: 20 × 6
##    country     continent  year lifeExp      pop gdpPercap
##    &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;
##  1 Afghanistan Asia       1952    28.8  8425333      779.
##  2 Afghanistan Asia       1957    30.3  9240934      821.
##  3 Afghanistan Asia       1962    32.0 10267083      853.
##  4 Afghanistan Asia       1967    34.0 11537966      836.
##  5 Afghanistan Asia       1972    36.1 13079460      740.
##  6 Afghanistan Asia       1977    38.4 14880372      786.
##  7 Afghanistan Asia       1982    39.9 12881816      978.
##  8 Afghanistan Asia       1987    40.8 13867957      852.
##  9 Afghanistan Asia       1992    41.7 16317921      649.
## 10 Afghanistan Asia       1997    41.8 22227415      635.
## 11 Afghanistan Asia       2002    42.1 25268405      727.
## 12 Afghanistan Asia       2007    43.8 31889923      975.
## 13 Albania     Europe     1952    55.2  1282697     1601.
## 14 Albania     Europe     1957    59.3  1476505     1942.
## 15 Albania     Europe     1962    64.8  1728137     2313.
## 16 Albania     Europe     1967    66.2  1984060     2760.
## 17 Albania     Europe     1972    67.7  2263554     3313.
## 18 Albania     Europe     1977    68.9  2509048     3533.
## 19 Albania     Europe     1982    70.4  2780097     3631.
## 20 Albania     Europe     1987    72    3075321     3739.</code></pre>
<pre class="r"><code>country_data &lt;- gapminder %&gt;% 
            filter(country == &quot;Italy&quot;) # just choosing Italy, as this is where I come from

continent_data &lt;- gapminder %&gt;% 
            filter(continent == &quot;Europe&quot;)</code></pre>
<pre class="r"><code>plot1 &lt;- ggplot(data = country_data, mapping = aes(x = year, y = lifeExp))+
  geom_point() +
  geom_smooth(se = FALSE)+
  NULL </code></pre>
<pre class="r"><code>plot1 &lt;- plot1 +
  labs(title = &quot;Life Expectancy in Italy from 1952 to 2007&quot;,
      x = &quot;Year&quot;,
      y = &quot;Life Expectancy&quot;) +
  NULL


plot1</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/lifeExp_one_country_with_label-1.png" width="672" /></p>
<pre class="r"><code> ggplot(data = continent_data, mapping = aes(x =  year, y = lifeExp  , colour = country, group = country))+
  geom_point() + 
  geom_smooth(se = FALSE) +
  NULL +
  ggtitle(&quot;Life Expectancy in Europe from 1952 to 2007&quot;)</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/lifeExp_one_continent-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = gapminder , mapping = aes(x = year, y = lifeExp, colour= country))+
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_wrap(~continent) +
  theme(legend.position=&quot;none&quot;) + #remove all legends
  NULL</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/lifeExp_facet_by_continent-1.png" width="672" /></p>
<p>With only minor exemptions (e.g. bump in Europe in the 80s, probably Baltic states), it is visible that life expectancy in the Americas, Europe and Oceania has increased fairly steadily. This data supports the common believe, that advancements in medicine and hygiene, stable nutrition supply, less wars and overall enhancements in quality of life have contributed to an increase in life expectancy.<br />
</p>
<p>In Asia and Africa, however, there is once again an overall trend to increasing life expectancy but fluctuations and exemptions are more common. Especially in some African countries we see a sharp decline in life expectancy starting from the 80s and 90s. It can be speculated that this is due to epidemics - especially HIV – but also due to civil wars or famines. The average life expectancy in Asia and Africa reached in 2007 is well below that of Europe and Oceania. The standard deviation is also higher, which leads to the conclusion that there are major difference among single countries.</p>
</div>
<div id="task-3-brexit-vote-analysis" class="section level1">
<h1>Task 3: Brexit vote analysis</h1>
<pre class="r"><code># read data directly off github repo
brexit_results &lt;- read_csv(&quot;https://raw.githubusercontent.com/kostis-christodoulou/am01/master/data/brexit_results.csv&quot;)


glimpse(brexit_results)</code></pre>
<pre><code>## Rows: 632
## Columns: 11
## $ Seat        &lt;chr&gt; &quot;Aldershot&quot;, &quot;Aldridge-Brownhills&quot;, &quot;Altrincham and Sale W…
## $ con_2015    &lt;dbl&gt; 50.592, 52.050, 52.994, 43.979, 60.788, 22.418, 52.454, 22…
## $ lab_2015    &lt;dbl&gt; 18.333, 22.369, 26.686, 34.781, 11.197, 41.022, 18.441, 49…
## $ ld_2015     &lt;dbl&gt; 8.824, 3.367, 8.383, 2.975, 7.192, 14.828, 5.984, 2.423, 1…
## $ ukip_2015   &lt;dbl&gt; 17.867, 19.624, 8.011, 15.887, 14.438, 21.409, 18.821, 21.…
## $ leave_share &lt;dbl&gt; 57.89777, 67.79635, 38.58780, 65.29912, 49.70111, 70.47289…
## $ born_in_uk  &lt;dbl&gt; 83.10464, 96.12207, 90.48566, 97.30437, 93.33793, 96.96214…
## $ male        &lt;dbl&gt; 49.89896, 48.92951, 48.90621, 49.21657, 48.00189, 49.17185…
## $ unemployed  &lt;dbl&gt; 3.637000, 4.553607, 3.039963, 4.261173, 2.468100, 4.742731…
## $ degree      &lt;dbl&gt; 13.870661, 9.974114, 28.600135, 9.336294, 18.775591, 6.085…
## $ age_18to24  &lt;dbl&gt; 9.406093, 7.325850, 6.437453, 7.747801, 5.734730, 8.209863…</code></pre>
<pre class="r"><code># histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_histogram(binwidth = 2.5) +
  labs(title = &quot;Histogram of leave % during Brexit Vote&quot;,
       subtitle = &quot;All constituencies&quot;,
       x = &quot;leave %-share&quot;,
       y = &quot;# constituencies&quot;)</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/brexit_histogram-1.png" width="672" /></p>
<pre class="r"><code># density plot-- think smoothed histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_density() + 
  labs(title = &quot;Density plot of leave % during Brexit Vote&quot;,
       subtitle = &quot;All constituencies&quot;,
       x = &quot;leave %-share&quot;,
       y = &quot;Constituencies density&quot;)</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/brexit_histogram-2.png" width="672" /></p>
<pre class="r"><code># The empirical cumulative distribution function (ECDF) 
ggplot(brexit_results, aes(x = leave_share)) +
  stat_ecdf(geom = &quot;step&quot;, pad = FALSE) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = &quot;Cumulative Distribution of leave % during Brexit Vote&quot;,
       subtitle = &quot;All constituencies&quot;,
       x = &quot;leave %-share&quot;,
       y = &quot;Cumulated share of constituencies&quot;)</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/brexit_histogram-3.png" width="672" /></p>
<pre class="r"><code>brexit_results %&gt;% 
  select(leave_share, born_in_uk) %&gt;% 
  cor()</code></pre>
<pre><code>##             leave_share born_in_uk
## leave_share   1.0000000  0.4934295
## born_in_uk    0.4934295  1.0000000</code></pre>
<p>The correlation is almost 0.5, which shows that the two variables are
positively correlated.</p>
<pre class="r"><code>ggplot(brexit_results, aes(x = born_in_uk, y = leave_share)) +
  geom_point(alpha=0.3) +
  
  # add a smoothing line, and use method=&quot;lm&quot; to get the best straight-line
  geom_smooth(method = &quot;lm&quot;) + 
  
  # use a white background and frame the plot with a black box
  theme_bw() +
  
  # Add titles
  labs(title = &quot;Relationship between native borne residents and leave share&quot;,
       subtitle = &quot;All constituencies&quot;,
       x = &quot;native borne uk residents %-share&quot;,
       y = &quot;leave %-share&quot;) +
  NULL</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/brexit_immigration_plot-1.png" width="672" /></p>
<p>The graph shows a correlation (0.5) between the % of native born residents within a constituency and its leave %-share. A large bulk of constituencies has a born_in_uk rate of 90% and above whereby the average of leave %-share among this majority-group seems to lie around 55%. In constituencies where the % of native born residents is below 80% on the other hand, the average submitted votes would have kept the UK within the EU. These findings support the statement that patriotic, UK born citizens are more likely to oppose the EU and its regulations (among which looser immigration policies).<br />
</p>
<p>However, a significant standard deviation can be observed across all %-shares of native borne uk residents. In other words, this means that two constituencies with a similiar 80% “native share” have voted in favor of Brexit with 70% as well as 20%. Thus, it is suggested not to regard native born % and fear of immigration as only explanation for the Brexit outcome.</p>
</div>
<div id="task-4-animal-rescue-incidents-attended-by-the-london-fire-brigade" class="section level1">
<h1>Task 4: Animal rescue incidents attended by the London Fire Brigade</h1>
<pre class="r"><code>url &lt;- &quot;https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/f43b485e-fb35-419c-aa7a-fa75676e5835/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv&quot;


animal_rescue &lt;- read_csv(url,
                          locale = locale(encoding = &quot;CP1252&quot;)) %&gt;% 
  janitor::clean_names()


glimpse(animal_rescue)</code></pre>
<pre><code>## Rows: 8,751
## Columns: 31
## $ incident_number               &lt;chr&gt; &quot;139091&quot;, &quot;275091&quot;, &quot;2075091&quot;, &quot;2872091&quot;…
## $ date_time_of_call             &lt;chr&gt; &quot;01/01/2009 03:01&quot;, &quot;01/01/2009 08:51&quot;, …
## $ cal_year                      &lt;dbl&gt; 2009, 2009, 2009, 2009, 2009, 2009, 2009…
## $ fin_year                      &lt;chr&gt; &quot;2008/09&quot;, &quot;2008/09&quot;, &quot;2008/09&quot;, &quot;2008/0…
## $ type_of_incident              &lt;chr&gt; &quot;Special Service&quot;, &quot;Special Service&quot;, &quot;S…
## $ pump_count                    &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, …
## $ pump_hours_total              &lt;chr&gt; &quot;2&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, …
## $ hourly_notional_cost          &lt;dbl&gt; 255, 255, 255, 255, 255, 255, 255, 255, …
## $ incident_notional_cost        &lt;chr&gt; &quot;510&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;…
## $ final_description             &lt;chr&gt; &quot;Redacted&quot;, &quot;Redacted&quot;, &quot;Redacted&quot;, &quot;Red…
## $ animal_group_parent           &lt;chr&gt; &quot;Dog&quot;, &quot;Fox&quot;, &quot;Dog&quot;, &quot;Horse&quot;, &quot;Rabbit&quot;, …
## $ originof_call                 &lt;chr&gt; &quot;Person (land line)&quot;, &quot;Person (land line…
## $ property_type                 &lt;chr&gt; &quot;House - single occupancy&quot;, &quot;Railings&quot;, …
## $ property_category             &lt;chr&gt; &quot;Dwelling&quot;, &quot;Outdoor Structure&quot;, &quot;Outdoo…
## $ special_service_type_category &lt;chr&gt; &quot;Other animal assistance&quot;, &quot;Other animal…
## $ special_service_type          &lt;chr&gt; &quot;Animal assistance involving livestock -…
## $ ward_code                     &lt;chr&gt; &quot;E05011467&quot;, &quot;E05000169&quot;, &quot;E05000558&quot;, &quot;…
## $ ward                          &lt;chr&gt; &quot;Crystal Palace &amp; Upper Norwood&quot;, &quot;Woods…
## $ borough_code                  &lt;chr&gt; &quot;E09000008&quot;, &quot;E09000008&quot;, &quot;E09000029&quot;, &quot;…
## $ borough                       &lt;chr&gt; &quot;Croydon&quot;, &quot;Croydon&quot;, &quot;Sutton&quot;, &quot;Hilling…
## $ stn_ground_name               &lt;chr&gt; &quot;Norbury&quot;, &quot;Woodside&quot;, &quot;Wallington&quot;, &quot;Ru…
## $ uprn                          &lt;chr&gt; &quot;NULL&quot;, &quot;NULL&quot;, &quot;NULL&quot;, &quot;1.00E+11&quot;, &quot;NUL…
## $ street                        &lt;chr&gt; &quot;Waddington Way&quot;, &quot;Grasmere Road&quot;, &quot;Mill…
## $ usrn                          &lt;chr&gt; &quot;20500146&quot;, &quot;NULL&quot;, &quot;NULL&quot;, &quot;21401484&quot;, …
## $ postcode_district             &lt;chr&gt; &quot;SE19&quot;, &quot;SE25&quot;, &quot;SM5&quot;, &quot;UB9&quot;, &quot;RM3&quot;, &quot;RM…
## $ easting_m                     &lt;chr&gt; &quot;NULL&quot;, &quot;534785&quot;, &quot;528041&quot;, &quot;504689&quot;, &quot;N…
## $ northing_m                    &lt;chr&gt; &quot;NULL&quot;, &quot;167546&quot;, &quot;164923&quot;, &quot;190685&quot;, &quot;N…
## $ easting_rounded               &lt;dbl&gt; 532350, 534750, 528050, 504650, 554650, …
## $ northing_rounded              &lt;dbl&gt; 170050, 167550, 164950, 190650, 192350, …
## $ latitude                      &lt;chr&gt; &quot;NULL&quot;, &quot;51.39095371&quot;, &quot;51.36894086&quot;, &quot;5…
## $ longitude                     &lt;chr&gt; &quot;NULL&quot;, &quot;-0.064166887&quot;, &quot;-0.161985191&quot;, …</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  dplyr::group_by(cal_year) %&gt;% 
  summarise(count=n())</code></pre>
<pre><code>## # A tibble: 14 × 2
##    cal_year count
##       &lt;dbl&gt; &lt;int&gt;
##  1     2009   568
##  2     2010   611
##  3     2011   620
##  4     2012   603
##  5     2013   585
##  6     2014   583
##  7     2015   540
##  8     2016   604
##  9     2017   539
## 10     2018   610
## 11     2019   604
## 12     2020   758
## 13     2021   885
## 14     2022   641</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  count(cal_year, name=&quot;count&quot;)</code></pre>
<pre><code>## # A tibble: 14 × 2
##    cal_year count
##       &lt;dbl&gt; &lt;int&gt;
##  1     2009   568
##  2     2010   611
##  3     2011   620
##  4     2012   603
##  5     2013   585
##  6     2014   583
##  7     2015   540
##  8     2016   604
##  9     2017   539
## 10     2018   610
## 11     2019   604
## 12     2020   758
## 13     2021   885
## 14     2022   641</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  group_by(animal_group_parent) %&gt;% 
  
  #group_by and summarise will produce a new column with the count in each animal group
  summarise(count = n()) %&gt;% 
  
  # mutate adds a new column; here we calculate the percentage
  mutate(percent = round(100*count/sum(count),2)) %&gt;% 
  
  # arrange() sorts the data by percent. Since the default sorting is min to max and we would like to see it sorted
  # in descending order (max to min), we use arrange(desc()) 
  arrange(desc(percent))</code></pre>
<pre><code>## # A tibble: 28 × 3
##    animal_group_parent              count percent
##    &lt;chr&gt;                            &lt;int&gt;   &lt;dbl&gt;
##  1 Cat                               4232   48.4 
##  2 Bird                              1803   20.6 
##  3 Dog                               1341   15.3 
##  4 Fox                                455    5.2 
##  5 Unknown - Domestic Animal Or Pet   215    2.46
##  6 Horse                              201    2.3 
##  7 Deer                               152    1.74
##  8 Unknown - Wild Animal              102    1.17
##  9 Squirrel                            75    0.86
## 10 Unknown - Heavy Livestock Animal    50    0.57
## # … with 18 more rows</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  
  #count does the same thing as group_by and summarise
  # name = &quot;count&quot; will call the column with the counts &quot;count&quot; ( exciting, I know)
  # and &#39;sort=TRUE&#39; will sort them from max to min
  count(animal_group_parent, name=&quot;count&quot;, sort=TRUE) %&gt;% 
  mutate(percent = round(100*count/sum(count),2))</code></pre>
<pre><code>## # A tibble: 28 × 3
##    animal_group_parent              count percent
##    &lt;chr&gt;                            &lt;int&gt;   &lt;dbl&gt;
##  1 Cat                               4232   48.4 
##  2 Bird                              1803   20.6 
##  3 Dog                               1341   15.3 
##  4 Fox                                455    5.2 
##  5 Unknown - Domestic Animal Or Pet   215    2.46
##  6 Horse                              201    2.3 
##  7 Deer                               152    1.74
##  8 Unknown - Wild Animal              102    1.17
##  9 Squirrel                            75    0.86
## 10 Unknown - Heavy Livestock Animal    50    0.57
## # … with 18 more rows</code></pre>
<pre class="r"><code># what type is variable incident_notional_cost from dataframe `animal_rescue`
typeof(animal_rescue$incident_notional_cost)</code></pre>
<pre><code>## [1] &quot;character&quot;</code></pre>
<pre class="r"><code># readr::parse_number() will convert any numerical values stored as characters into numbers
animal_rescue &lt;- animal_rescue %&gt;% 

  # we use mutate() to use the parse_number() function and overwrite the same variable
  mutate(incident_notional_cost = parse_number(incident_notional_cost))

# incident_notional_cost from dataframe `animal_rescue` is now &#39;double&#39; or numeric
typeof(animal_rescue$incident_notional_cost)</code></pre>
<pre><code>## [1] &quot;double&quot;</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  
  # group by animal_group_parent
  group_by(animal_group_parent) %&gt;% 
  
  # filter resulting data, so each group has at least 6 observations
  filter(n()&gt;6) %&gt;% 
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost, na.rm=TRUE),
            count = n()) %&gt;% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(mean_incident_cost))</code></pre>
<pre><code>## # A tibble: 17 × 7
##    animal_group_parent             mean_…¹ media…² sd_in…³ min_i…⁴ max_i…⁵ count
##    &lt;chr&gt;                             &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;
##  1 Horse                              735.    596    536.      255    3480   201
##  2 Cow                                599.    436    451.      260    1560     9
##  3 Unknown - Wild Animal              422.    333    318.      260    2296   102
##  4 Deer                               421.    339    276.      260    2340   152
##  5 Fox                                382.    339    200.      255    2034   455
##  6 Snake                              375.    352    122.      260     704    20
##  7 Unknown - Heavy Livestock Anim…    374.    260    263.      255    1560    50
##  8 Sheep                              355.    339    114.      255     596     7
##  9 Dog                                353.    326    182.        0    3168  1341
## 10 Cat                                351.    326    163.        0    3912  4232
## 11 Bird                               349.    328    138.      255    1788  1803
## 12 Unknown - Domestic Animal Or P…    331.    298    119.      255    1300   215
## 13 cat                                329.    310.    87.4     260     596    20
## 14 Squirrel                           318.    328     55.6     255     678    75
## 15 Hamster                            317.    290     92.5     260     652    17
## 16 Rabbit                             315.    330.    34.4     255     364    16
## 17 Ferret                             314.    336     41.1     260     364    10
## # … with abbreviated variable names ¹​mean_incident_cost, ²​median_incident_cost,
## #   ³​sd_incident_cost, ⁴​min_incident_cost, ⁵​max_incident_cost</code></pre>
<p>Median usually lower, this lets us conclude that we have outliers on the top end of the cost range (single animals very difficult to rescue).</p>
<pre class="r"><code># base_plot
base_plot &lt;- animal_rescue %&gt;% 
  group_by(animal_group_parent) %&gt;% 
  filter(n()&gt;6) %&gt;% 
  ggplot(aes(x=incident_notional_cost))+
  facet_wrap(~animal_group_parent, scales = &quot;free&quot;)+
  theme_bw()

base_plot + geom_histogram()</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/plots_on_incident_cost_by_animal_group-1.png" width="672" /></p>
<pre class="r"><code>base_plot + geom_density()</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/plots_on_incident_cost_by_animal_group-2.png" width="672" /></p>
<pre class="r"><code>base_plot + geom_boxplot()</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/plots_on_incident_cost_by_animal_group-3.png" width="672" /></p>
<pre class="r"><code>base_plot + stat_ecdf(geom = &quot;step&quot;, pad = FALSE) +
  scale_y_continuous(labels = scales::percent)</code></pre>
<p><img src="/blogs/pre_course_files/figure-html/plots_on_incident_cost_by_animal_group-4.png" width="672" /></p>
<p>Variability is best shown in the boxplot graph as single outliers get lost in the other graphs due to the significant number of observations. 
As expected, large animals such as horses, cows, and deer are on average the most expensive to rescue. It is speculated that it takes more working-hours and machinery to recover heavier animals. While the minimal cost is similiar across the categories, the maximum cost seams to have some positive correlation with animal size. 
Correspondingly, the sd is significant in these categories, with the maximum value as high as 10x the median rescue cost. Animals such as Rabbits and Ferrets have the least outliers, a fact that could lead to the conclusion that the rescue effort for these animals is fairly predictable.</p>
</div>
