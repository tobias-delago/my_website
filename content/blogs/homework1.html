---
title: "Group 11 Workshop 1"
description: "1st Homework within Applied Statistics with R class"
slug: homework1
image: 
keywords: ""
categories: 
    - ""
    - ""
date: 2022-08-31
draft: false
---



<div id="rents-in-san-francisco-2000-2018" class="section level1">
<h1>Rents in San Francisco 2000-2018</h1>
<pre class="r"><code># download directly off tidytuesdaygithub repo

rent &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-07-05/rent.csv&#39;)</code></pre>
<div id="what-are-the-variable-types-do-they-all-correspond-to-what-they-really-are-which-variables-have-most-missing-values" class="section level2">
<h2>What are the variable types? Do they all correspond to what they really are? Which variables have most missing values?</h2>
<pre class="r"><code>skim(rent)</code></pre>
<table>
<caption>(#tab:skim_data)Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">rent</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">200796</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">17</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">8</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">9</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<colgroup>
<col width="18%" />
<col width="13%" />
<col width="18%" />
<col width="5%" />
<col width="8%" />
<col width="8%" />
<col width="12%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">post_id</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">9</td>
<td align="right">14</td>
<td align="right">0</td>
<td align="right">200796</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">nhood</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">4</td>
<td align="right">43</td>
<td align="right">0</td>
<td align="right">167</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">city</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">5</td>
<td align="right">19</td>
<td align="right">0</td>
<td align="right">104</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">county</td>
<td align="right">1394</td>
<td align="right">0.99</td>
<td align="right">4</td>
<td align="right">13</td>
<td align="right">0</td>
<td align="right">10</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">address</td>
<td align="right">196888</td>
<td align="right">0.02</td>
<td align="right">1</td>
<td align="right">38</td>
<td align="right">0</td>
<td align="right">2869</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">title</td>
<td align="right">2517</td>
<td align="right">0.99</td>
<td align="right">2</td>
<td align="right">298</td>
<td align="right">0</td>
<td align="right">184961</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">descr</td>
<td align="right">197542</td>
<td align="right">0.02</td>
<td align="right">13</td>
<td align="right">16975</td>
<td align="right">0</td>
<td align="right">3025</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">details</td>
<td align="right">192780</td>
<td align="right">0.04</td>
<td align="right">4</td>
<td align="right">595</td>
<td align="right">0</td>
<td align="right">7667</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<colgroup>
<col width="11%" />
<col width="8%" />
<col width="11%" />
<col width="10%" />
<col width="7%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">date</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">20095718.38</td>
<td align="right">44694.07</td>
<td align="right">20000902.0</td>
<td align="right">20050227.0</td>
<td align="right">20110924.0</td>
<td align="right">20120805.0</td>
<td align="right">20180717.0</td>
<td align="left">▁▇▁▆▃</td>
</tr>
<tr class="even">
<td align="left">year</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">2009.51</td>
<td align="right">4.48</td>
<td align="right">2000.0</td>
<td align="right">2005.0</td>
<td align="right">2011.0</td>
<td align="right">2012.0</td>
<td align="right">2018.0</td>
<td align="left">▁▇▁▆▃</td>
</tr>
<tr class="odd">
<td align="left">price</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">2135.36</td>
<td align="right">1427.75</td>
<td align="right">220.0</td>
<td align="right">1295.0</td>
<td align="right">1800.0</td>
<td align="right">2505.0</td>
<td align="right">40000.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">beds</td>
<td align="right">6608</td>
<td align="right">0.97</td>
<td align="right">1.89</td>
<td align="right">1.08</td>
<td align="right">0.0</td>
<td align="right">1.0</td>
<td align="right">2.0</td>
<td align="right">3.0</td>
<td align="right">12.0</td>
<td align="left">▇▂▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">baths</td>
<td align="right">158121</td>
<td align="right">0.21</td>
<td align="right">1.68</td>
<td align="right">0.69</td>
<td align="right">1.0</td>
<td align="right">1.0</td>
<td align="right">2.0</td>
<td align="right">2.0</td>
<td align="right">8.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">sqft</td>
<td align="right">136117</td>
<td align="right">0.32</td>
<td align="right">1201.83</td>
<td align="right">5000.22</td>
<td align="right">80.0</td>
<td align="right">750.0</td>
<td align="right">1000.0</td>
<td align="right">1360.0</td>
<td align="right">900000.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">room_in_apt</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">0.00</td>
<td align="right">0.04</td>
<td align="right">0.0</td>
<td align="right">0.0</td>
<td align="right">0.0</td>
<td align="right">0.0</td>
<td align="right">1.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">lat</td>
<td align="right">193145</td>
<td align="right">0.04</td>
<td align="right">37.67</td>
<td align="right">0.35</td>
<td align="right">33.6</td>
<td align="right">37.4</td>
<td align="right">37.8</td>
<td align="right">37.8</td>
<td align="right">40.4</td>
<td align="left">▁▁▅▇▁</td>
</tr>
<tr class="odd">
<td align="left">lon</td>
<td align="right">196484</td>
<td align="right">0.02</td>
<td align="right">-122.21</td>
<td align="right">0.78</td>
<td align="right">-123.2</td>
<td align="right">-122.4</td>
<td align="right">-122.3</td>
<td align="right">-122.0</td>
<td align="right">-74.2</td>
<td align="left">▇▁▁▁▁</td>
</tr>
</tbody>
</table>
<pre class="r"><code>glimpse(rent)</code></pre>
<pre><code>## Rows: 200,796
## Columns: 17
## $ post_id     &lt;chr&gt; &quot;pre2013_134138&quot;, &quot;pre2013_135669&quot;, &quot;pre2013_127127&quot;, &quot;pre…
## $ date        &lt;dbl&gt; 20050111, 20050126, 20041017, 20120601, 20041021, 20060411…
## $ year        &lt;dbl&gt; 2005, 2005, 2004, 2012, 2004, 2006, 2007, 2017, 2009, 2006…
## $ nhood       &lt;chr&gt; &quot;alameda&quot;, &quot;alameda&quot;, &quot;alameda&quot;, &quot;alameda&quot;, &quot;alameda&quot;, &quot;al…
## $ city        &lt;chr&gt; &quot;alameda&quot;, &quot;alameda&quot;, &quot;alameda&quot;, &quot;alameda&quot;, &quot;alameda&quot;, &quot;al…
## $ county      &lt;chr&gt; &quot;alameda&quot;, &quot;alameda&quot;, &quot;alameda&quot;, &quot;alameda&quot;, &quot;alameda&quot;, &quot;al…
## $ price       &lt;dbl&gt; 1250, 1295, 1100, 1425, 890, 825, 1500, 2925, 450, 1395, 1…
## $ beds        &lt;dbl&gt; 2, 2, 2, 1, 1, 1, 1, 3, NA, 2, 2, 5, 4, 0, 4, 1, 3, 3, 1, …
## $ baths       &lt;dbl&gt; 2, NA, NA, NA, NA, NA, 1, NA, 1, NA, NA, NA, 3, NA, NA, NA…
## $ sqft        &lt;dbl&gt; NA, NA, NA, 735, NA, NA, NA, NA, NA, NA, NA, 2581, 1756, N…
## $ room_in_apt &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
## $ address     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ lat         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 37.5, NA, …
## $ lon         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ title       &lt;chr&gt; &quot;$1250 / 2br - 2BR/2BA   1145 ALAMEDA DE LAS PULGAS&quot;, &quot;$12…
## $ descr       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ details     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;&lt;p class=…</code></pre>
<p><strong>Answer:</strong></p>
<ul>
<li>Variable types: chr &amp; dbl<br />
</li>
<li>Do they correspond: Date could be formatted as &lt; date &gt;<br />
</li>
<li>Most missing variable: descr (197542)<br />
</li>
</ul>
</div>
<div id="make-a-plot-that-shows-the-top-20-cities-in-terms-of-of-classifieds-between-2000-2018.-you-need-to-calculate-the-number-of-listings-by-city-and-then-convert-that-number-to-a-." class="section level2">
<h2>Make a plot that shows the top 20 cities in terms of % of classifieds between 2000-2018. You need to calculate the number of listings by city, and then convert that number to a %.</h2>
<p><strong>The final graph should look like this:</strong><br />
</p>
<p><img src="images/top_cities.png" /></p>
<pre class="r"><code>top20 &lt;- rent %&gt;% 
  count(city, sort=TRUE) %&gt;% 
  mutate(proportion = n/sum(n)) %&gt;% 
  slice_max(order_by = proportion, n=20) %&gt;% 
  mutate(city = fct_reorder(city, proportion))
  
ggplot(data = top20, mapping = aes(x=proportion, y=city)) +
  geom_col() +
  labs(
    title = &quot;San Francisco accounts for more than a quarter of all rental classifieds&quot;,
    subtitle = &quot;% of Craigslist listings, 2000-2018&quot;,
    x = NULL,
    y = NULL,
    caption=&quot;Source: Pennigton, Kate (2018). Bay Area Craiglist Rental Housing Posts, 2000-2018&quot;
  ) +
  scale_x_continuous(labels = scales::percent) +
  theme_light() +
  theme(panel.border = element_blank())+
  theme(plot.title = element_text(hjust = -0.35))+
  theme(plot.subtitle = element_text(hjust = -0.15))</code></pre>
<p><img src="/blogs/homework1_files/figure-html/top_cities-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<div id="make-a-plot-that-shows-the-evolution-of-median-prices-in-san-francisco-for-0-1-2-and-3-bedrooms-listings." class="section level2">
<h2>Make a plot that shows the evolution of median prices in San Francisco for 0, 1, 2, and 3 bedrooms listings.</h2>
<p><strong>The final graph should look like this</strong><br />
</p>
<p><img src="images/sf_rentals.png" /></p>
<pre class="r"><code>median_per_bed &lt;- rent %&gt;% 
  filter(beds &lt;= 3, city == &quot;san francisco&quot;) %&gt;% 
  group_by(beds, year) %&gt;% 
  summarize(median_price = median(price))

ggplot(median_per_bed, aes(x=year, y=median_price, color = factor(beds))) +
  geom_line() +
  facet_wrap(~beds, nrow = 1) +
  labs(
    title = &quot;San Francisco rents have steadily been increasing&quot;,
    subtitle = &quot;0 to 3-bed listings, 2000-2018&quot;,
    x=NULL,
    y=NULL,
    caption = &quot;Source: Pennigton, Kate (2018). Bay Area Craiglist Rental Housing Posts, 2000-2018&quot;
  ) +
  xlim(2003,2018) +
  theme_light() +
  theme(legend.position=&quot;none&quot;) +
  theme(plot.title = element_text(hjust = 0))+
  theme(plot.subtitle = element_text(hjust = 0)) +
  theme(strip.text.x = element_text(colour = &quot;black&quot;)) +
  theme(panel.border = element_rect(color = &quot;black&quot;, fill = NA, size = 0.5)) +
  theme(strip.background = element_rect(color = &quot;black&quot;, size = 0.5))</code></pre>
<p><img src="/blogs/homework1_files/figure-html/sf_median_prices-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<div id="finally-make-a-plot-that-shows-median-rental-prices-for-the-top-12-cities-in-the-bay-area." class="section level2">
<h2>Finally, make a plot that shows median rental prices for the top 12 cities in the Bay area.</h2>
<p><strong>Your final graph should look like this:</strong><br />
</p>
<p><img src="images/one_bed_bay_area.png" /></p>
<pre class="r"><code>cities_to_include &lt;- rent %&gt;% 
  group_by(city) %&gt;% 
  summarize(number_ads = n()) %&gt;%
  slice_max(order_by = number_ads, n=12)

cities_to_include &lt;- cities_to_include$city

median_per_bed &lt;- rent %&gt;% 
  filter(beds == 1, city %in% cities_to_include) %&gt;% 
  group_by(city, year) %&gt;% 
  summarize(median_price = median(price)) 

ggplot(median_per_bed, aes(x=year, y=median_price, color = factor(city))) +
  geom_line() +
  facet_wrap(~city, nrow = 3) +
  labs(
    title = &quot;Rental prices for 1-bedroom flats in the Bay Area&quot;,
    x=NULL,
    y=NULL,
    caption=&quot;Source: Pennigton, Kate (2018). Bay Area Craiglist Rental Housing Posts, 2000-2018&quot;
  ) +
  theme_light() +
  theme(legend.position=&quot;none&quot;) +
  theme(plot.title = element_text(hjust = 0)) +
  theme(strip.text.x = element_text(colour = &quot;black&quot;)) +
  theme(panel.border = element_rect(color = &quot;black&quot;, fill = NA, size = 0.5)) +
  theme(strip.background = element_rect(color = &quot;black&quot;, size = 0.5))</code></pre>
<p><img src="/blogs/homework1_files/figure-html/spirit_plot-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<div id="what-can-you-infer-from-these-plots-dont-just-explain-whats-in-the-graph-but-speculate-or-tell-a-short-story-1-2-paragraphs-max." class="section level2">
<h2>What can you infer from these plots? Don’t just explain what’s in the graph, but speculate or tell a short story (1-2 paragraphs max).</h2>
<p>Looking at the graphs from the last exercise we can see that rental prices have increased since the year 2000. While one major cause could be inflation, it is also true that large tech companies have increased the attractiveness of the Bay Area making living there more expensive.<br />
The figures also reveal that there has been a decline in the growth rate (or even negative growth) in the median rent after 2015. It could be due to the fact that more and more people are leaving California as the boom seems to lose momentum. A CNBC <a href="https://www.youtube.com/watch?v=Ez90rXhMWjE">video</a> outlines the reasons for this exodus of people.<br />
</p>
</div>
</div>
<div id="analysis-of-movies--imdb-dataset" class="section level1">
<h1>Analysis of movies- IMDB dataset</h1>
<pre class="r"><code># warning=FALSE, message=FALSE, eval=FALSE

movies &lt;- read_csv(here::here(&quot;data&quot;, &quot;movies.csv&quot;))</code></pre>
<div id="are-there-any-missing-values-nas-are-all-entries-distinct-or-are-there-duplicate-entries" class="section level2">
<h2>Are there any missing values (NAs)? Are all entries distinct or are there duplicate entries?</h2>
<pre class="r"><code># Counts the NA for each row and outputs only rows with at least one NA, all columns outputted
movies[rowSums(is.na(movies))!=0,]</code></pre>
<pre><code>## # A tibble: 0 × 11
## # … with 11 variables: title &lt;chr&gt;, genre &lt;chr&gt;, director &lt;chr&gt;, year &lt;dbl&gt;,
## #   duration &lt;dbl&gt;, gross &lt;dbl&gt;, budget &lt;dbl&gt;, cast_facebook_likes &lt;dbl&gt;,
## #   votes &lt;dbl&gt;, reviews &lt;dbl&gt;, rating &lt;dbl&gt;</code></pre>
<pre class="r"><code>#Find duplicate entries by looking at title
#movies[duplicated(movies$title) | duplicated(movies$title, fromLast=TRUE),]

nam&lt;-movies$title
numb&lt;- 1:2961
dt1&lt;-data.frame(name=nam,number=numb)
duplicated_name=dt1 %&gt;% 
  group_by(name) %&gt;% 
  summarise(freq=n()) %&gt;% 
  filter(freq&gt;1) %&gt;% 
  select(name)
duplicated_name</code></pre>
<pre><code>## # A tibble: 53 × 1
##    name                       
##    &lt;chr&gt;                      
##  1 A Nightmare on Elm Street  
##  2 Across the Universe        
##  3 Alice in Wonderland        
##  4 Aloha                      
##  5 Around the World in 80 Days
##  6 Brothers                   
##  7 Carrie                     
##  8 Chasing Liberty            
##  9 Cinderella                 
## 10 Clash of the Titans        
## # … with 43 more rows</code></pre>
<pre class="r"><code># Find if completely the same:
any(duplicated(movies))</code></pre>
<pre><code>## [1] FALSE</code></pre>
<p><strong>Answer</strong>:</p>
<p>There are no missing values but various double/triple entries (107 rows affected). To go more detail which movies are affected, please see the table above to find the name list. However, none of these entries is exactly the same on all variables.</p>
</div>
<div id="produce-a-table-with-the-count-of-movies-by-genre-ranked-in-descending-order" class="section level2">
<h2>Produce a table with the count of movies by genre, ranked in descending order</h2>
<pre class="r"><code>kable(movies %&gt;% 
  group_by(genre) %&gt;% 
  summarise(count_per_genre = n()) %&gt;% 
  arrange(desc(count_per_genre)), caption=&quot;Ranking Specified By Movies Genre&quot;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-3">Table 1: </span>Ranking Specified By Movies Genre</caption>
<thead>
<tr class="header">
<th align="left">genre</th>
<th align="right">count_per_genre</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Comedy</td>
<td align="right">848</td>
</tr>
<tr class="even">
<td align="left">Action</td>
<td align="right">738</td>
</tr>
<tr class="odd">
<td align="left">Drama</td>
<td align="right">498</td>
</tr>
<tr class="even">
<td align="left">Adventure</td>
<td align="right">288</td>
</tr>
<tr class="odd">
<td align="left">Crime</td>
<td align="right">202</td>
</tr>
<tr class="even">
<td align="left">Biography</td>
<td align="right">135</td>
</tr>
<tr class="odd">
<td align="left">Horror</td>
<td align="right">131</td>
</tr>
<tr class="even">
<td align="left">Animation</td>
<td align="right">35</td>
</tr>
<tr class="odd">
<td align="left">Fantasy</td>
<td align="right">28</td>
</tr>
<tr class="even">
<td align="left">Documentary</td>
<td align="right">25</td>
</tr>
<tr class="odd">
<td align="left">Mystery</td>
<td align="right">16</td>
</tr>
<tr class="even">
<td align="left">Sci-Fi</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="left">Family</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">Musical</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Romance</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Western</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Thriller</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<pre class="r"><code>#movies %&gt;% 
#count(genre) %&gt;% 
#arrange(desc(n))</code></pre>
</div>
<div id="produce-a-table-with-the-average-gross-earning-and-budget-gross-and-budget-by-genre.-calculate-a-variable-return_on_budget-which-shows-how-many-did-a-movie-make-at-the-box-office-for-each-of-its-budget.-ranked-genres-by-this-return_on_budget-in-descending-order" class="section level2">
<h2>Produce a table with the average gross earning and budget (<code>gross</code> and <code>budget</code>) by genre. Calculate a variable <code>return_on_budget</code> which shows how many $ did a movie make at the box office for each $ of its budget. Ranked genres by this <code>return_on_budget</code> in descending order</h2>
<pre class="r"><code>kable(movies %&gt;% 
  group_by(genre) %&gt;% 
  summarize(mean_gross_earning= mean(gross), mean_budget = mean(budget)) %&gt;% 
  mutate(return_on_budget = mean_gross_earning/mean_budget) %&gt;% 
  arrange(desc(return_on_budget)), caption = &quot;Profit Ability Specified By Movies Genre [$]&quot;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-4">Table 2: </span>Profit Ability Specified By Movies Genre [$]</caption>
<thead>
<tr class="header">
<th align="left">genre</th>
<th align="right">mean_gross_earning</th>
<th align="right">mean_budget</th>
<th align="right">return_on_budget</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Musical</td>
<td align="right">92084000</td>
<td align="right">3189500</td>
<td align="right">28.871</td>
</tr>
<tr class="even">
<td align="left">Family</td>
<td align="right">149160478</td>
<td align="right">14833333</td>
<td align="right">10.056</td>
</tr>
<tr class="odd">
<td align="left">Western</td>
<td align="right">20821884</td>
<td align="right">3465000</td>
<td align="right">6.009</td>
</tr>
<tr class="even">
<td align="left">Documentary</td>
<td align="right">17353973</td>
<td align="right">5887852</td>
<td align="right">2.947</td>
</tr>
<tr class="odd">
<td align="left">Horror</td>
<td align="right">37713738</td>
<td align="right">13504916</td>
<td align="right">2.793</td>
</tr>
<tr class="even">
<td align="left">Fantasy</td>
<td align="right">42408841</td>
<td align="right">17582143</td>
<td align="right">2.412</td>
</tr>
<tr class="odd">
<td align="left">Comedy</td>
<td align="right">42630552</td>
<td align="right">24446319</td>
<td align="right">1.744</td>
</tr>
<tr class="even">
<td align="left">Mystery</td>
<td align="right">67533021</td>
<td align="right">39218750</td>
<td align="right">1.722</td>
</tr>
<tr class="odd">
<td align="left">Animation</td>
<td align="right">98433792</td>
<td align="right">61701429</td>
<td align="right">1.595</td>
</tr>
<tr class="even">
<td align="left">Biography</td>
<td align="right">45201805</td>
<td align="right">28543696</td>
<td align="right">1.584</td>
</tr>
<tr class="odd">
<td align="left">Adventure</td>
<td align="right">95794257</td>
<td align="right">66290069</td>
<td align="right">1.445</td>
</tr>
<tr class="even">
<td align="left">Drama</td>
<td align="right">37465371</td>
<td align="right">26242933</td>
<td align="right">1.428</td>
</tr>
<tr class="odd">
<td align="left">Crime</td>
<td align="right">37502397</td>
<td align="right">26596169</td>
<td align="right">1.410</td>
</tr>
<tr class="even">
<td align="left">Romance</td>
<td align="right">31264849</td>
<td align="right">25107500</td>
<td align="right">1.245</td>
</tr>
<tr class="odd">
<td align="left">Action</td>
<td align="right">86583860</td>
<td align="right">71354888</td>
<td align="right">1.213</td>
</tr>
<tr class="even">
<td align="left">Sci-Fi</td>
<td align="right">29788371</td>
<td align="right">27607143</td>
<td align="right">1.079</td>
</tr>
<tr class="odd">
<td align="left">Thriller</td>
<td align="right">2468</td>
<td align="right">300000</td>
<td align="right">0.008</td>
</tr>
</tbody>
</table>
</div>
<div id="produce-a-table-that-shows-the-top-15-directors-who-have-created-the-highest-gross-revenue-in-the-box-office.-dont-just-show-the-total-gross-amount-but-also-the-mean-median-and-standard-deviation-per-director." class="section level2">
<h2>Produce a table that shows the top 15 directors who have created the highest gross revenue in the box office. Don’t just show the total gross amount, but also the mean, median, and standard deviation per director.</h2>
<pre class="r"><code>kable(movies %&gt;% 
  group_by(director) %&gt;% 
  summarize(total_gross = sum(gross), mean_gross = mean(gross), median_gross = median(gross), sd_gross = sd(gross)) %&gt;% 
  arrange(desc(total_gross)) %&gt;% 
  slice_max(order_by = total_gross, n=15), caption = &quot;Most Profitable Directors Ranking [$]&quot;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-5">Table 3: </span>Most Profitable Directors Ranking [$]</caption>
<thead>
<tr class="header">
<th align="left">director</th>
<th align="right">total_gross</th>
<th align="right">mean_gross</th>
<th align="right">median_gross</th>
<th align="right">sd_gross</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Steven Spielberg</td>
<td align="right">4014061704</td>
<td align="right">174524422</td>
<td align="right">164435221</td>
<td align="right">101421051</td>
</tr>
<tr class="even">
<td align="left">Michael Bay</td>
<td align="right">2231242537</td>
<td align="right">171634041</td>
<td align="right">138396624</td>
<td align="right">127161579</td>
</tr>
<tr class="odd">
<td align="left">Tim Burton</td>
<td align="right">2071275480</td>
<td align="right">129454718</td>
<td align="right">76519172</td>
<td align="right">108726924</td>
</tr>
<tr class="even">
<td align="left">Sam Raimi</td>
<td align="right">2014600898</td>
<td align="right">201460090</td>
<td align="right">234903076</td>
<td align="right">162126632</td>
</tr>
<tr class="odd">
<td align="left">James Cameron</td>
<td align="right">1909725910</td>
<td align="right">318287652</td>
<td align="right">175562881</td>
<td align="right">309171337</td>
</tr>
<tr class="even">
<td align="left">Christopher Nolan</td>
<td align="right">1813227576</td>
<td align="right">226653447</td>
<td align="right">196667607</td>
<td align="right">187224133</td>
</tr>
<tr class="odd">
<td align="left">George Lucas</td>
<td align="right">1741418480</td>
<td align="right">348283696</td>
<td align="right">380262555</td>
<td align="right">146193880</td>
</tr>
<tr class="even">
<td align="left">Robert Zemeckis</td>
<td align="right">1619309108</td>
<td align="right">124562239</td>
<td align="right">100853835</td>
<td align="right">91300279</td>
</tr>
<tr class="odd">
<td align="left">Clint Eastwood</td>
<td align="right">1378321100</td>
<td align="right">72543216</td>
<td align="right">46700000</td>
<td align="right">75487408</td>
</tr>
<tr class="even">
<td align="left">Francis Lawrence</td>
<td align="right">1358501971</td>
<td align="right">271700394</td>
<td align="right">281666058</td>
<td align="right">135437020</td>
</tr>
<tr class="odd">
<td align="left">Ron Howard</td>
<td align="right">1335988092</td>
<td align="right">111332341</td>
<td align="right">101587923</td>
<td align="right">81933761</td>
</tr>
<tr class="even">
<td align="left">Gore Verbinski</td>
<td align="right">1329600995</td>
<td align="right">189942999</td>
<td align="right">123207194</td>
<td align="right">154473822</td>
</tr>
<tr class="odd">
<td align="left">Andrew Adamson</td>
<td align="right">1137446920</td>
<td align="right">284361730</td>
<td align="right">279680931</td>
<td align="right">120895765</td>
</tr>
<tr class="even">
<td align="left">Shawn Levy</td>
<td align="right">1129750988</td>
<td align="right">102704635</td>
<td align="right">85463309</td>
<td align="right">65484773</td>
</tr>
<tr class="odd">
<td align="left">Ridley Scott</td>
<td align="right">1128857598</td>
<td align="right">80632686</td>
<td align="right">47775715</td>
<td align="right">68812285</td>
</tr>
</tbody>
</table>
</div>
<div id="finally-ratings.-produce-a-table-that-describes-how-ratings-are-distributed-by-genre.-we-dont-want-just-the-mean-but-also-min-max-median-sd-and-some-kind-of-a-histogram-or-density-graph-that-visually-shows-how-ratings-are-distributed." class="section level2">
<h2>Finally, ratings. Produce a table that describes how ratings are distributed by genre. We don’t want just the mean, but also, min, max, median, SD and some kind of a histogram or density graph that visually shows how ratings are distributed.</h2>
<pre class="r"><code>kable(movies %&gt;% 
  group_by(genre) %&gt;% 
  summarize(mean_rating = mean(rating), min_rating = min(rating), max_rating=max(rating), median_rating=median(rating),sd_rating = sd(rating), number_ratings=n()) %&gt;% 
  arrange(desc(mean_rating)), caption = &quot;Rating Specified By Movies Genre&quot;, digits = 1)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-6">Table 4: </span>Rating Specified By Movies Genre</caption>
<colgroup>
<col width="14%" />
<col width="14%" />
<col width="12%" />
<col width="12%" />
<col width="16%" />
<col width="11%" />
<col width="17%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">genre</th>
<th align="right">mean_rating</th>
<th align="right">min_rating</th>
<th align="right">max_rating</th>
<th align="right">median_rating</th>
<th align="right">sd_rating</th>
<th align="right">number_ratings</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Biography</td>
<td align="right">7.1</td>
<td align="right">4.5</td>
<td align="right">8.9</td>
<td align="right">7.2</td>
<td align="right">0.8</td>
<td align="right">135</td>
</tr>
<tr class="even">
<td align="left">Crime</td>
<td align="right">6.9</td>
<td align="right">4.8</td>
<td align="right">9.3</td>
<td align="right">6.9</td>
<td align="right">0.8</td>
<td align="right">202</td>
</tr>
<tr class="odd">
<td align="left">Mystery</td>
<td align="right">6.9</td>
<td align="right">4.6</td>
<td align="right">8.5</td>
<td align="right">6.9</td>
<td align="right">0.9</td>
<td align="right">16</td>
</tr>
<tr class="even">
<td align="left">Musical</td>
<td align="right">6.8</td>
<td align="right">6.3</td>
<td align="right">7.2</td>
<td align="right">6.8</td>
<td align="right">0.6</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Drama</td>
<td align="right">6.7</td>
<td align="right">2.1</td>
<td align="right">8.8</td>
<td align="right">6.8</td>
<td align="right">0.9</td>
<td align="right">498</td>
</tr>
<tr class="even">
<td align="left">Documentary</td>
<td align="right">6.7</td>
<td align="right">1.6</td>
<td align="right">8.5</td>
<td align="right">7.4</td>
<td align="right">1.8</td>
<td align="right">25</td>
</tr>
<tr class="odd">
<td align="left">Sci-Fi</td>
<td align="right">6.7</td>
<td align="right">5.0</td>
<td align="right">8.2</td>
<td align="right">6.4</td>
<td align="right">1.1</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="left">Animation</td>
<td align="right">6.7</td>
<td align="right">4.5</td>
<td align="right">8.0</td>
<td align="right">6.9</td>
<td align="right">1.0</td>
<td align="right">35</td>
</tr>
<tr class="odd">
<td align="left">Romance</td>
<td align="right">6.7</td>
<td align="right">6.2</td>
<td align="right">7.1</td>
<td align="right">6.7</td>
<td align="right">0.6</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">Adventure</td>
<td align="right">6.5</td>
<td align="right">2.3</td>
<td align="right">8.6</td>
<td align="right">6.6</td>
<td align="right">1.1</td>
<td align="right">288</td>
</tr>
<tr class="odd">
<td align="left">Family</td>
<td align="right">6.5</td>
<td align="right">5.7</td>
<td align="right">7.9</td>
<td align="right">5.9</td>
<td align="right">1.2</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">Action</td>
<td align="right">6.2</td>
<td align="right">2.1</td>
<td align="right">9.0</td>
<td align="right">6.3</td>
<td align="right">1.0</td>
<td align="right">738</td>
</tr>
<tr class="odd">
<td align="left">Fantasy</td>
<td align="right">6.2</td>
<td align="right">4.3</td>
<td align="right">7.9</td>
<td align="right">6.4</td>
<td align="right">1.0</td>
<td align="right">28</td>
</tr>
<tr class="even">
<td align="left">Comedy</td>
<td align="right">6.1</td>
<td align="right">1.9</td>
<td align="right">8.8</td>
<td align="right">6.2</td>
<td align="right">1.0</td>
<td align="right">848</td>
</tr>
<tr class="odd">
<td align="left">Horror</td>
<td align="right">5.8</td>
<td align="right">3.6</td>
<td align="right">8.5</td>
<td align="right">5.9</td>
<td align="right">1.0</td>
<td align="right">131</td>
</tr>
<tr class="even">
<td align="left">Western</td>
<td align="right">5.7</td>
<td align="right">4.1</td>
<td align="right">7.3</td>
<td align="right">5.7</td>
<td align="right">2.3</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">Thriller</td>
<td align="right">4.8</td>
<td align="right">4.8</td>
<td align="right">4.8</td>
<td align="right">4.8</td>
<td align="right">NA</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<pre class="r"><code>movies_filtered &lt;- movies %&gt;% 
  filter(genre != &quot;Thriller&quot;)

ggplot(movies_filtered, aes(x = rating)) +
  geom_density() +
  facet_wrap(~genre, nrow = 4) +
  labs(
    title = &quot;Ratings Distribution By Genre&quot;,
    subtitle = &quot;Only thriller rating = 4.8&quot;, y=&quot;density&quot;,
    caption = &quot;Source: Kaggle IMDB 5000 movie dataset&quot;
  ) +
  theme_light() +
  theme(strip.text = element_text(colour = &quot;black&quot;)) +
  theme(panel.border = element_rect(color = &quot;black&quot;, fill = NA, size = 0.5)) +
  theme(strip.background = element_rect(color = &quot;black&quot;, size = 0.5))</code></pre>
<p><img src="/blogs/homework1_files/figure-html/unnamed-chunk-7-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(movies, aes(x = rating)) +
  geom_histogram(color=&quot;white&quot;, fill = &quot;#CB454A&quot;) +
  labs(
    title = &quot;Ratings Distribution total&quot;,
    y=&quot;quantity&quot;,
    caption = &quot;Source: Kaggle IMDB 5000 movie dataset&quot;
  ) +
  theme_light()</code></pre>
<p><img src="/blogs/homework1_files/figure-html/unnamed-chunk-7-2.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<div id="examine-the-relationship-between-gross-and-cast_facebook_likes.-produce-a-scatterplot-and-write-one-sentence-discussing-whether-the-number-of-facebook-likes-that-the-cast-has-received-is-likely-to-be-a-good-predictor-of-how-much-money-a-movie-will-make-at-the-box-office.-what-variable-are-you-going-to-map-to-the-y--and-x--axes" class="section level2">
<h2>Examine the relationship between <code>gross</code> and <code>cast_facebook_likes</code>. Produce a scatterplot and write one sentence discussing whether the number of facebook likes that the cast has received is likely to be a good predictor of how much money a movie will make at the box office. What variable are you going to map to the Y- and X- axes?</h2>
<pre class="r"><code>ggplot(movies, aes(x = cast_facebook_likes, y = gross)) +
  geom_point() +
  xlim(0,100000) +
  geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;#CB454A&quot;) +
  labs(
    title=&quot;Correlation Between Cast Facebook Likes And Movie Revenue&quot;, y= &quot;Gross profit in $&quot;, x=&quot;Facebook Like Received&quot;,
    caption = &quot;Source: Kaggle IMDB 5000 movie dataset&quot;
  )+
  theme_light()</code></pre>
<p><img src="/blogs/homework1_files/figure-html/gross_on_fblikes-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>correlation_likes &lt;- cor(movies$cast_facebook_likes,movies$gross)
correlation_likes</code></pre>
<pre><code>## [1] 0.213</code></pre>
<p><strong>Answer:</strong></p>
<p>Although there is a minor tendency, the available data does not lead to the conclusion that cast facebook likes are a clear predictor for how much money the movie will make (correlation &lt; 0.3)</p>
</div>
<div id="examine-the-relationship-between-gross-and-budget.-produce-a-scatterplot-and-write-one-sentence-discussing-whether-budget-is-likely-to-be-a-good-predictor-of-how-much-money-a-movie-will-make-at-the-box-office." class="section level2">
<h2>Examine the relationship between <code>gross</code> and <code>budget</code>. Produce a scatterplot and write one sentence discussing whether budget is likely to be a good predictor of how much money a movie will make at the box office.</h2>
<pre class="r"><code>ggplot(movies, aes(x = budget, y = gross)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;#CB454A&quot;)+
  labs(
    title=&quot;Correlation Between Budget And Movie Revenue&quot;, y= &quot;Gross profit in $&quot;, x=&quot;Buget Used in $&quot;,
    caption = &quot;Source: Kaggle IMDB 5000 movie dataset&quot;)+
  theme_light()</code></pre>
<p><img src="/blogs/homework1_files/figure-html/gross_on_budget-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>correlation_budget &lt;- cor(movies$budget,movies$gross)
correlation_budget</code></pre>
<pre><code>## [1] 0.641</code></pre>
<p><strong>Answer:</strong></p>
<p>Although there are some outliers, budget seems to be a fairly good predictor of how much money the movie will make (correlation above 0.5)<br />
</p>
</div>
<div id="examine-the-relationship-between-gross-and-rating.-produce-a-scatterplot-faceted-by-genre-and-discuss-whether-imdb-ratings-are-likely-to-be-a-good-predictor-of-how-much-money-a-movie-will-make-at-the-box-office.-is-there-anything-strange-in-this-dataset" class="section level2">
<h2>Examine the relationship between <code>gross</code> and <code>rating</code>. Produce a scatterplot, faceted by <code>genre</code> and discuss whether IMDB ratings are likely to be a good predictor of how much money a movie will make at the box office. Is there anything strange in this dataset?</h2>
<pre class="r"><code>ggplot(movies_filtered, aes(x = rating, y = gross)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;#CB454A&quot;)+
  labs(
    title=&quot;Correlation Between Rating And Movie Revenue Specified By Genre&quot;, y= &quot;Gross profit in $&quot;, x=&quot;Rating&quot;,
    caption = &quot;Source: Kaggle IMDB 5000 movie dataset&quot;
  ) +
  facet_wrap(~genre, scales=&quot;free&quot;)+
#  theme(axis.text.y=element_blank())
  theme_light()</code></pre>
<p><img src="/blogs/homework1_files/figure-html/gross_on_rating-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>correlation_rating &lt;- cor(movies$rating,movies$gross)
correlation_rating</code></pre>
<pre><code>## [1] 0.269</code></pre>
<p><strong>Answer:</strong></p>
<p>There is no overall tendency that the higher the ratings, the higher the gross revenue (correlation &lt; 0.3) - some genres e.g. documentary or Sci-Fi even have a negative relationship.<br />
</p>
</div>
</div>
<div id="returns-of-financial-stocks" class="section level1">
<h1>Returns of financial stocks</h1>
<pre class="r"><code>nyse &lt;- read_csv(here::here(&quot;data&quot;,&quot;nyse.csv&quot;))</code></pre>
<div id="based-on-this-dataset-create-a-table-and-a-bar-plot-that-shows-the-number-of-companies-per-sector-in-descending-order" class="section level2">
<h2>Based on this dataset, create a table and a bar plot that shows the number of companies per sector, in descending order</h2>
<pre class="r"><code>nyse_sectors &lt;- nyse %&gt;% 
  count(sector, sort=TRUE) %&gt;% 
  mutate(sector = fct_reorder(sector, n))

kable(nyse_sectors, caption = &quot;Number of Companies per Sector&quot;)</code></pre>
<table>
<caption>(#tab:companies_per_sector)Number of Companies per Sector</caption>
<thead>
<tr class="header">
<th align="left">sector</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Finance</td>
<td align="right">97</td>
</tr>
<tr class="even">
<td align="left">Consumer Services</td>
<td align="right">79</td>
</tr>
<tr class="odd">
<td align="left">Public Utilities</td>
<td align="right">60</td>
</tr>
<tr class="even">
<td align="left">Capital Goods</td>
<td align="right">45</td>
</tr>
<tr class="odd">
<td align="left">Health Care</td>
<td align="right">45</td>
</tr>
<tr class="even">
<td align="left">Energy</td>
<td align="right">42</td>
</tr>
<tr class="odd">
<td align="left">Technology</td>
<td align="right">40</td>
</tr>
<tr class="even">
<td align="left">Basic Industries</td>
<td align="right">39</td>
</tr>
<tr class="odd">
<td align="left">Consumer Non-Durables</td>
<td align="right">31</td>
</tr>
<tr class="even">
<td align="left">Miscellaneous</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">Transportation</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="left">Consumer Durables</td>
<td align="right">8</td>
</tr>
</tbody>
</table>
<pre class="r"><code>ggplot(nyse_sectors, aes(x = n, y = sector)) +
  geom_col(fill = &quot;#CB454A&quot;) + 
  labs(
    title =&quot;Number of Companies per Sector&quot;, 
    x=&quot;number of companies&quot;,
    y=&quot;sectors&quot;,
    caption = &quot;Kostis Christodoulou (2022) Finance Data&quot;
     )</code></pre>
<p><img src="/blogs/homework1_files/figure-html/companies_per_sector-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Notice the cache=TRUE argument inthe chunk options. Because getting data is time consuming, 
# cache=TRUE means that once it downloads data, the chunk will not run again next time you knit your Rmd

myStocks &lt;- c(&quot;AAPL&quot;, &quot;JPM&quot;, &quot;DIS&quot;,&quot;DPZ&quot;,&quot;ANF&quot;,&quot;TSLA&quot;,&quot;SPY&quot; ) %&gt;%
  tq_get(get  = &quot;stock.prices&quot;,
         from = &quot;2011-01-01&quot;,
         to   = &quot;2022-08-31&quot;) %&gt;%
  group_by(symbol) 

glimpse(myStocks) # examine the structure of the resulting data frame</code></pre>
<pre><code>## Rows: 20,545
## Columns: 8
## Groups: symbol [7]
## $ symbol   &lt;chr&gt; &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL&quot;, &quot;AAPL…
## $ date     &lt;date&gt; 2011-01-03, 2011-01-04, 2011-01-05, 2011-01-06, 2011-01-07, …
## $ open     &lt;dbl&gt; 11.6, 11.9, 11.8, 12.0, 11.9, 12.1, 12.3, 12.3, 12.3, 12.4, 1…
## $ high     &lt;dbl&gt; 11.8, 11.9, 11.9, 12.0, 12.0, 12.3, 12.3, 12.3, 12.4, 12.4, 1…
## $ low      &lt;dbl&gt; 11.6, 11.7, 11.8, 11.9, 11.9, 12.0, 12.1, 12.2, 12.3, 12.3, 1…
## $ close    &lt;dbl&gt; 11.8, 11.8, 11.9, 11.9, 12.0, 12.2, 12.2, 12.3, 12.3, 12.4, 1…
## $ volume   &lt;dbl&gt; 445138400, 309080800, 255519600, 300428800, 311931200, 448560…
## $ adjusted &lt;dbl&gt; 10.05, 10.10, 10.18, 10.18, 10.25, 10.44, 10.42, 10.50, 10.54…</code></pre>
<pre class="r"><code>#calculate daily returns
myStocks_returns_daily &lt;- myStocks %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;daily&quot;, 
               type       = &quot;log&quot;,
               col_rename = &quot;daily_returns&quot;,
               cols = c(nested.col)) 

#calculate monthly  returns
myStocks_returns_monthly &lt;- myStocks %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;monthly&quot;, 
               type       = &quot;arithmetic&quot;,
               col_rename = &quot;monthly_returns&quot;,
               cols = c(nested.col)) 

#calculate yearly returns
myStocks_returns_annual &lt;- myStocks %&gt;%
  #group_by(symbol) %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;yearly&quot;, 
               type       = &quot;arithmetic&quot;,
               col_rename = &quot;yearly_returns&quot;,
               cols = c(nested.col))</code></pre>
</div>
<div id="create-a-table-where-you-summarise-monthly-returns-for-each-of-the-stocks-and-spy-min-max-median-mean-sd." class="section level2">
<h2>Create a table where you summarise monthly returns for each of the stocks and <code>SPY</code>; min, max, median, mean, SD.</h2>
<pre class="r"><code>kable(myStocks_returns_monthly %&gt;% 
  group_by(symbol) %&gt;% 
  summarize(min_return = min(monthly_returns), max_return = max(monthly_returns), median_return = median(monthly_returns), mean_return = mean(monthly_returns), sd_return = sd(monthly_returns)), caption = &quot;Monthly Returns for Stocks&quot;)</code></pre>
<table>
<caption>(#tab:summarise_monthly_returns)Monthly Returns for Stocks</caption>
<thead>
<tr class="header">
<th align="left">symbol</th>
<th align="right">min_return</th>
<th align="right">max_return</th>
<th align="right">median_return</th>
<th align="right">mean_return</th>
<th align="right">sd_return</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">AAPL</td>
<td align="right">-0.181</td>
<td align="right">0.217</td>
<td align="right">0.023</td>
<td align="right">0.023</td>
<td align="right">0.079</td>
</tr>
<tr class="even">
<td align="left">ANF</td>
<td align="right">-0.421</td>
<td align="right">0.507</td>
<td align="right">0.001</td>
<td align="right">0.003</td>
<td align="right">0.146</td>
</tr>
<tr class="odd">
<td align="left">DIS</td>
<td align="right">-0.186</td>
<td align="right">0.234</td>
<td align="right">0.007</td>
<td align="right">0.011</td>
<td align="right">0.072</td>
</tr>
<tr class="even">
<td align="left">DPZ</td>
<td align="right">-0.194</td>
<td align="right">0.342</td>
<td align="right">0.025</td>
<td align="right">0.027</td>
<td align="right">0.077</td>
</tr>
<tr class="odd">
<td align="left">JPM</td>
<td align="right">-0.229</td>
<td align="right">0.202</td>
<td align="right">0.020</td>
<td align="right">0.012</td>
<td align="right">0.073</td>
</tr>
<tr class="even">
<td align="left">SPY</td>
<td align="right">-0.125</td>
<td align="right">0.127</td>
<td align="right">0.015</td>
<td align="right">0.011</td>
<td align="right">0.040</td>
</tr>
<tr class="odd">
<td align="left">TSLA</td>
<td align="right">-0.224</td>
<td align="right">0.811</td>
<td align="right">0.012</td>
<td align="right">0.050</td>
<td align="right">0.177</td>
</tr>
</tbody>
</table>
</div>
<div id="plot-a-density-plot-using-geom_density-for-each-of-the-stocks" class="section level2">
<h2>Plot a density plot, using <code>geom_density()</code>, for each of the stocks</h2>
<pre class="r"><code>ggplot(myStocks_returns_monthly, aes(x=monthly_returns)) +
  geom_density() +
  facet_wrap(~symbol) + 
  labs(
    title =&quot;Density plot of monthly returns for each stock&quot;, 
    x=&quot;monthly returns&quot;,
    y=&quot;density&quot;,
    caption = &quot;Kostis Christodoulou (2022) Finance Data&quot;
     )</code></pre>
<p><img src="/blogs/homework1_files/figure-html/density_monthly_returns-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<div id="what-can-you-infer-from-this-plot-which-stock-is-the-riskiest-the-least-risky" class="section level2">
<h2>What can you infer from this plot? Which stock is the riskiest? The least risky?</h2>
<p><strong>Answer:</strong></p>
<p>This density plot shows the distribution of the companies’ monthly returns. A broad curve with greater spread means that we have a large variance in outcome and thus higher risk. Therefore, it appears that Tesla is the riskiest asset in our portfolio as it has a very large spread of monthly returns and the maximum density of a possible return value is below 3. As a tech company, Tesla faces great business uncertainties (e.g. technologicla breakthroughs). SP500 ETF is the least risky one, as a “spike” is shown in the diagram, its monthly returns are very concentrated, reaching the density above 12. Meanwhile its spread is very narrow. This is because the stock is an index ETF which is made up by the selected index stocks in the market and generally reflects the risk of the entire stock market across multiple industries which diversifies the risk.</p>
</div>
<div id="finally-make-a-plot-that-shows-the-expected-monthly-return-mean-of-a-stock-on-the-y-axis-and-the-risk-standard-deviation-in-the-x-axis.-please-use-ggrepelgeom_text_repel-to-label-each-stock" class="section level2">
<h2>Finally, make a plot that shows the expected monthly return (mean) of a stock on the Y axis and the risk (standard deviation) in the X-axis. Please use <code>ggrepel::geom_text_repel()</code> to label each stock</h2>
<pre class="r"><code>mean_sd_return &lt;- myStocks_returns_monthly %&gt;% 
  group_by(symbol) %&gt;% 
  summarize(mean_return = mean(monthly_returns), sd_return = sd(monthly_returns))

ggplot(mean_sd_return, aes(x=sd_return, y = mean_return, label=symbol))+
  geom_point(shape=23, fill=&quot;black&quot;) +
  geom_text_repel(fontface = &quot;bold&quot;) +
  labs(
    title = &quot;return vs risk of stocks&quot;, 
    x=&quot;standard deviation of monthly return&quot;,
    y=&quot;mean of monthly return&quot;,
    caption = &quot;Kostis Christodoulou (2022) Finance Data&quot;
  ) </code></pre>
<p><img src="/blogs/homework1_files/figure-html/risk_return_plot-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<div id="what-can-you-infer-from-this-plot-are-there-any-stocks-which-while-being-riskier-do-not-have-a-higher-expected-return" class="section level2">
<h2>What can you infer from this plot? Are there any stocks which, while being riskier, do not have a higher expected return?</h2>
<p><strong>Answer:</strong></p>
<p>Standard deviation can be used to show the volatility of the stocks, and therefore the risks beared by the investors. Most companies’ stocks follow the rule of “risk vs return”, which means that those with higher risks should generate higher returns to compensate. For examples, S&amp;P 500 ETF generates less risk for less return whearas Tesla generates extremely high return for high risk. Other stocks similarly follow this rule. However, Abercrombie &amp; Fitch is risky but still provides low returns. This poor performance aligns with the bad news on the company over the recent years, including the declining sales from 2020 to 2022, scandals of discriminatory hiring practices, store closure etc.</p>
</div>
</div>
<div id="on-your-own-spotify" class="section level1">
<h1>On your own: Spotify</h1>
<blockquote>
<p>Still waiting to get my Data request approved by Spotify to set up own API</p>
</blockquote>
<pre class="r"><code>spotify_songs &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv&#39;)</code></pre>
<div id="what-is-the-distribution-of-songs-popularity-track_popularity.-does-it-look-like-a-normal-distribution" class="section level2">
<h2>What is the distribution of songs’ popularity (<code>track_popularity</code>). Does it look like a Normal distribution?</h2>
<pre class="r"><code>ggplot(spotify_songs, aes(x = track_popularity)) +
  geom_histogram(bins= 50, color = &quot;white&quot;, fill = &quot;#CB454A&quot;)+
  labs(title = &quot;Distribution of track popularity&quot;, x = NULL,
    y = NULL,
    caption = &quot;Source: Jthomasmock (2020). Spotify Songs&quot;
  ) +
   theme_light()</code></pre>
<p><img src="/blogs/homework1_files/figure-html/unnamed-chunk-8-1.png" width="864" style="display: block; margin: auto;" /></p>
<p><strong>Answer:</strong></p>
<p>The distribution of songs’ popularity almost looks like a normal distribution, but we can observe some significant outliers on the extreme left and around 50.</p>
</div>
<div id="how-are-audio-features-distributed-can-you-roughly-guess-which-of-these-variables-is-closer-to-normal-just-by-looking-at-summary-statistics" class="section level2">
<h2>How are audio-features distributed? can you roughly guess which of these variables is closer to Normal just by looking at summary statistics?</h2>
<pre class="r"><code>spotify_songs_filtered &lt;- spotify_songs %&gt;% 
  select(c(&quot;danceability&quot;, &quot;energy&quot;, &quot;key&quot;, &quot;loudness&quot;, &quot;mode&quot;, &quot;speechiness&quot;, &quot;acousticness&quot;,
           &quot;instrumentalness&quot;, &quot;liveness&quot;, &quot;valence&quot;, &quot;tempo&quot;, &quot;duration_ms&quot;))

ggplot(gather(spotify_songs_filtered), aes(value)) + 
    geom_histogram(bins = 100, fill = &quot;#CB454A&quot;) +
  labs(title = &quot;Distribution for each feature&quot;, x = NULL,
    y = NULL,
    caption = &quot;Source: Jthomasmock (2020). Spotify Songs&quot;
  ) +
   theme_light()+
    facet_wrap(~key, scales=&quot;free&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/unnamed-chunk-9-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary(spotify_songs_filtered)</code></pre>
<pre><code>##   danceability       energy           key           loudness    
##  Min.   :0.000   Min.   :0.000   Min.   : 0.00   Min.   :-46.4  
##  1st Qu.:0.563   1st Qu.:0.581   1st Qu.: 2.00   1st Qu.: -8.2  
##  Median :0.672   Median :0.721   Median : 6.00   Median : -6.2  
##  Mean   :0.655   Mean   :0.699   Mean   : 5.37   Mean   : -6.7  
##  3rd Qu.:0.761   3rd Qu.:0.840   3rd Qu.: 9.00   3rd Qu.: -4.6  
##  Max.   :0.983   Max.   :1.000   Max.   :11.00   Max.   :  1.3  
##       mode        speechiness     acousticness   instrumentalness
##  Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000   
##  1st Qu.:0.000   1st Qu.:0.041   1st Qu.:0.015   1st Qu.:0.000   
##  Median :1.000   Median :0.062   Median :0.080   Median :0.000   
##  Mean   :0.566   Mean   :0.107   Mean   :0.175   Mean   :0.085   
##  3rd Qu.:1.000   3rd Qu.:0.132   3rd Qu.:0.255   3rd Qu.:0.005   
##  Max.   :1.000   Max.   :0.918   Max.   :0.994   Max.   :0.994   
##     liveness        valence          tempo      duration_ms    
##  Min.   :0.000   Min.   :0.000   Min.   :  0   Min.   :  4000  
##  1st Qu.:0.093   1st Qu.:0.331   1st Qu.:100   1st Qu.:187819  
##  Median :0.127   Median :0.512   Median :122   Median :216000  
##  Mean   :0.190   Mean   :0.511   Mean   :121   Mean   :225800  
##  3rd Qu.:0.248   3rd Qu.:0.693   3rd Qu.:134   3rd Qu.:253585  
##  Max.   :0.996   Max.   :0.991   Max.   :239   Max.   :517810</code></pre>
<p><strong>Answer:</strong></p>
<p>It can be guessed by summary statistics how the data is distributed (histogram or additional tests such as Shapiro Wilk Test would yield higher precision). In order to be normally distributed, the mean and the median should almost be the same. Then regarding the quartiles, they should be at an equal distance from the median.<br />
From the data, we can see that acousticness as well as speechiness aren’t normally distributed at all, significantly skewed to the right. On the other hand, duration and danceability are distributed more normally.</p>
</div>
<div id="is-there-any-relationship-between-valence-and-track_popularity-danceability-and-track_popularity" class="section level2">
<h2>Is there any relationship between <code>valence</code> and <code>track_popularity</code>? <code>danceability</code> and <code>track_popularity</code> ?</h2>
<pre class="r"><code>spotify_songs %&gt;% 
  ggplot( aes(x = valence, y = track_popularity)) +
  geom_point(alpha = .05) +
  geom_smooth(color = &quot;#CB454A&quot;, se=F)+
  labs(title = &quot;Relationship between Valence and Track popularity&quot;,
       x=&quot;Valence&quot;,
       y=&quot;Track Popularity&quot;,
       caption = &quot;Source: Jthomasmock (2020). Spotify Songs&quot;)+
  theme_light()</code></pre>
<p><img src="/blogs/homework1_files/figure-html/unnamed-chunk-11-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>correlation_rating_valence &lt;- cor(spotify_songs$valence,spotify_songs$track_popularity)
correlation_rating_valence</code></pre>
<pre><code>## [1] 0.0332</code></pre>
<pre class="r"><code>spotify_songs %&gt;% 
  ggplot( aes(x = danceability, y = track_popularity)) +
  geom_point(alpha = .05) +
  geom_smooth(color = &quot;#CB454A&quot;, se=F)+
  labs(title = &quot;Relationship between Danceability and Track popularity&quot;,
       x=&quot;Danceability&quot;,
       y=&quot;Track Popularity&quot;,
       caption = &quot;Source: Jthomasmock (2020). Spotify Songs&quot;)+
  theme_light()</code></pre>
<p><img src="/blogs/homework1_files/figure-html/unnamed-chunk-11-2.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>correlation_rating_danceability &lt;- cor(spotify_songs$danceability,spotify_songs$track_popularity)
correlation_rating_danceability</code></pre>
<pre><code>## [1] 0.0647</code></pre>
<p><strong>Answer:</strong></p>
<p>The correlation between valence and track popularity is 0.0332, which is very low, indicating no relationship between these variables. The plot among these variables supports this observation. The plot of variables for danceability and track popularity shows they are not correlated as depicted by the regression line. The correlation among these variables is 0.0647, which supports our observation.</p>
</div>
<div id="do-songs-written-on-a-major-scale-have-higher-danceability-compared-to-those-in-minor-scale-what-about-track_popularity" class="section level2">
<h2>Do songs written on a major scale have higher <code>danceability</code> compared to those in minor scale? What about <code>track_popularity</code>?</h2>
<pre class="r"><code>spotify_songs %&gt;% 
  ggplot(aes(danceability))+
  geom_boxplot()+
  coord_flip()+
  #geom_histogram(bins=50, color = &quot;white&quot;, fill = &quot;#CB454A&quot;)+
  labs(title = &quot;Modal comparison for Daceability (mean as vertical line&quot;,
       x=&quot;Danceability&quot;,
       y=NULL,
       caption = &quot;Source: Jthomasmock (2020). Spotify Songs&quot;)+
  facet_wrap(~mode)+
  theme_light()+
  theme(legend.position=&quot;none&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/unnamed-chunk-12-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>  #geom_vline(aes(xintercept = mean(danceability)),col=&#39;black&#39;,size=1)

spotify_songs %&gt;% 
  group_by(mode) %&gt;% 
  summarize(mean_danceability = mean(danceability), median_danceability = median(danceability))</code></pre>
<pre><code>## # A tibble: 2 × 3
##    mode mean_danceability median_danceability
##   &lt;dbl&gt;             &lt;dbl&gt;               &lt;dbl&gt;
## 1     0             0.665               0.68 
## 2     1             0.647               0.663</code></pre>
<pre class="r"><code>spotify_songs %&gt;% 
  ggplot(aes(track_popularity))+
  geom_boxplot()+
  coord_flip()+
  #geom_histogram(bins=50, color = &quot;white&quot;, fill = &quot;#CB454A&quot;)+
  labs(title = &quot;Modal comparison for Track Popularity (mean as vertical line)&quot;,
       x=&quot;Popularity&quot;,
       y=NULL,
       caption = &quot;Source: Jthomasmock (2020). Spotify Songs&quot;)+
  facet_wrap(~mode)+
  theme_light()+
  theme(legend.position=&quot;none&quot;)</code></pre>
<p><img src="/blogs/homework1_files/figure-html/unnamed-chunk-12-2.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>  #geom_vline(aes(xintercept = mean(track_popularity)),col=&#39;black&#39;,size=1)

spotify_songs %&gt;% 
  group_by(mode) %&gt;% 
  summarize(mean_track_popularity = mean(track_popularity), median_track_popularity = median(track_popularity))</code></pre>
<pre><code>## # A tibble: 2 × 3
##    mode mean_track_popularity median_track_popularity
##   &lt;dbl&gt;                 &lt;dbl&gt;                   &lt;dbl&gt;
## 1     0                  42.2                      45
## 2     1                  42.7                      46</code></pre>
<p><strong>Answer:</strong></p>
<p>While almost the same, minor is slightly more danceable and major is slightly more popular.</p>
</div>
<div id="optional-additional-description-of-data-set" class="section level2">
<h2>Optional additional description of data set</h2>
<pre class="r"><code>famous &lt;- spotify_songs %&gt;% 
  group_by(track_artist) %&gt;% 
  summarize(mean_popularity = mean(track_popularity), n=n())

kable(famous %&gt;% 
  filter(n&gt;10) %&gt;% 
  slice_max(order_by = mean_popularity, n=10), caption = &quot;Artists with highest popularity (&gt;10 songs)&quot;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-13">Table 5: </span>Artists with highest popularity (&gt;10 songs)</caption>
<thead>
<tr class="header">
<th align="left">track_artist</th>
<th align="right">mean_popularity</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Roddy Ricch</td>
<td align="right">88.2</td>
<td align="right">19</td>
</tr>
<tr class="even">
<td align="left">DaBaby</td>
<td align="right">87.9</td>
<td align="right">14</td>
</tr>
<tr class="odd">
<td align="left">YNW Melly</td>
<td align="right">84.6</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="left">Lewis Capaldi</td>
<td align="right">83.7</td>
<td align="right">21</td>
</tr>
<tr class="odd">
<td align="left">MEDUZA</td>
<td align="right">83.6</td>
<td align="right">16</td>
</tr>
<tr class="even">
<td align="left">Harry Styles</td>
<td align="right">83.6</td>
<td align="right">27</td>
</tr>
<tr class="odd">
<td align="left">Billie Eilish</td>
<td align="right">83.6</td>
<td align="right">43</td>
</tr>
<tr class="even">
<td align="left">Travis Scott</td>
<td align="right">82.1</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="left">Regard</td>
<td align="right">80.6</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">Doja Cat</td>
<td align="right">79.9</td>
<td align="right">16</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="challenge-1-replicating-a-chart" class="section level1">
<h1>Challenge 1: Replicating a chart</h1>
<div id="you-have-to-create-a-graph-that-calculates-the-cumulative-change-for-0--1-1-and-2-bed-flats-between-2000-and-2018-for-the-top-twelve-cities-in-bay-area-by-number-of-ads-that-appeared-in-craigslist.-your-final-graph-should-look-like-this" class="section level2">
<h2>You have to create a graph that calculates the cumulative % change for 0-, 1-1, and 2-bed flats between 2000 and 2018 for the top twelve cities in Bay Area, by number of ads that appeared in Craigslist. Your final graph should look like this</h2>
<p><img src="images/challenge1.png" /></p>
<pre class="r"><code>cities_to_include &lt;- rent %&gt;% 
  group_by(city) %&gt;% 
  summarize(number_ads = n()) %&gt;%
  slice_max(order_by = number_ads, n=12)

cities_to_include &lt;- cities_to_include$city

filtered_rent &lt;- rent %&gt;% 
  filter(beds &lt;= 2, city %in% cities_to_include) %&gt;% 
  group_by(year, city, beds) %&gt;% 
  summarise(median_price =median(price)) %&gt;% 
  ungroup()

sorted &lt;- filtered_rent %&gt;% 
  arrange(beds, city, year)

rent_change &lt;- sorted %&gt;% 
  group_by(beds, city) %&gt;% 
  mutate(change_per_year = (median_price/(median_price[1L])))

ggplot(rent_change, aes(x=year, y = change_per_year, color = factor(city))) +
  geom_line() +
  facet_grid(beds~city, scales = &quot;free&quot;) +
  labs(
    title = &quot;Cumulative % change in 0, 1, and 2-bed rental in Bay Area&quot;,
    subtitle = &quot;2000-2018&quot;,
    x=&quot;&quot;,
    y=&quot;&quot;
  ) +
  ylim(0,250) +
  theme_light() +
  theme(legend.position=&quot;none&quot;)+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(strip.text.x = element_text(size = 6)) +
  scale_y_continuous(labels = scales::percent) +
  theme(strip.text = element_text(colour = &quot;black&quot;)) +
  theme(panel.border = element_rect(color = &quot;black&quot;, fill = NA, size = 0.5)) +
  theme(strip.background = element_rect(color = &quot;black&quot;, size = 0.5))</code></pre>
<p><img src="/blogs/homework1_files/figure-html/challenge%201-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="challenge-2-2016-california-contributors" class="section level1">
<h1>Challenge 2: 2016 California Contributors</h1>
<div id="as-discussed-in-class-i-would-like-you-to-reproduce-the-plot-that-shows-the-top-ten-cities-in-highest-amounts-raised-in-political-contributions-in-california-during-the-2016-us-presidential-election." class="section level2">
<h2>As discussed in class, I would like you to reproduce the plot that shows the top ten cities in highest amounts raised in political contributions in California during the 2016 US Presidential election.</h2>
<p><img src="../../images/challenge2.png" width="100%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Make sure you use vroom() as it is significantly faster than read.csv()
CA_contributors_2016 &lt;- vroom::vroom(here::here(&quot;data&quot;,&quot;CA_contributors_2016.csv&quot;))
zip_codes &lt;- vroom::vroom(here::here(&quot;data&quot;,&quot;zip_code_database.csv&quot;))</code></pre>
<pre class="r"><code>contributions_filtered &lt;- CA_contributors_2016 %&gt;% 
  filter(cand_nm == &quot;Clinton, Hillary Rodham&quot; | cand_nm == &quot;Trump, Donald J.&quot;) %&gt;% 
  mutate(zip = as.character(zip))

contributions_filtered &lt;- left_join(contributions_filtered, zip_codes, by=&quot;zip&quot;)

contributions_filtered %&gt;%
  group_by(cand_nm, primary_city) %&gt;%
  summarize(sum_donations = sum(contb_receipt_amt)) %&gt;%
  slice_max(order_by = sum_donations, n = 10) %&gt;% 
  ungroup %&gt;%
  mutate(cand_nm = as.factor(cand_nm), 
         primary_city = reorder_within(primary_city, sum_donations, cand_nm)) %&gt;% 
  ggplot(aes(x = sum_donations, y = primary_city, fill = factor(cand_nm))) +
    geom_col() +
    facet_wrap(~cand_nm, scales = &quot;free&quot;) +
    labs(
      title = &quot;Where did candidates rase most money&quot;,
      y = NULL,
      x = &quot;Amount raised&quot;
    ) +
    scale_y_reordered() +
    theme_light() +
    scale_fill_manual(values = c(&quot;#2E74C0&quot;, &quot;#CB454A&quot;)) +
    scale_x_continuous(labels=scales::dollar_format())+
    theme(legend.position=&quot;none&quot;) +
    theme(strip.text.x = element_text(colour = &quot;black&quot;)) +
    theme(panel.border = element_rect(color = &quot;black&quot;, fill = NA, size = 0.5)) +
    theme(strip.background = element_rect(color = &quot;black&quot;, size = 0.5))</code></pre>
<p><img src="/blogs/homework1_files/figure-html/elections-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="deliverables" class="section level1">
<h1>Deliverables</h1>
<p>There is a lot of explanatory text, comments, etc. You do not need these, so delete them and produce a stand-alone document that you could share with someone. Knit the edited and completed R Markdown file as an HTML document (use the “Knit” button at the top of the script editor window) and upload it to Canvas.</p>
</div>
<div id="details" class="section level1">
<h1>Details</h1>
<ul>
<li>Who did you collaborate with: Vani Duggal, Mehak Khanna, Manon Pillot, Nick Chen, Liyang Zhang, Tobias Delago</li>
<li>Approximately how much time did you spend on this problem set: 30h</li>
<li>What, if anything, gave you the most trouble: Challenge 1, plotting the cumulative % change, figuring out how to filter for the top 12 cities</li>
</ul>
<blockquote>
<p>As a true test to yourself, do you understand the code you submitted and are you able to explain it to someone else?</p>
</blockquote>
</div>
<div id="rubric" class="section level1">
<h1>Rubric</h1>
<p>Check minus (1/5): Displays minimal effort. Doesn’t complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn’t use plots appropriate for the variables being analyzed.</p>
<p>Check (3/5): Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output).</p>
<p>Check plus (5/5): Finished all components of the assignment correctly and addressed both challenges. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you’ve written additional text to describe how you interpret the output.</p>
</div>
